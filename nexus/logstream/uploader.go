package logstream

import (
	"context"
	"encoding/base64"
	"errors"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"sync"
	"sync/atomic"

	"cybros.ai/nexus/client"
	"cybros.ai/nexus/protocol"
)

// TokenFunc returns the current directive token. It is called on every
// log-chunk upload so that the uploader always uses the latest token
// (refreshed by the heartbeat loop).
type TokenFunc func() string

type Uploader struct {
	cli         *client.Client
	directiveID string
	tokenFn     TokenFunc

	chunkBytes int
	maxBytes   int64

	stdoutSeq int32
	stderrSeq int32

	totalBytes int64

	stdoutTruncated atomic.Bool
	stderrTruncated atomic.Bool

	overflowEnabled bool
	overflowDir     string

	stdoutOverflow overflowStream
	stderrOverflow overflowStream
}

func New(cli *client.Client, directiveID string, tokenFn TokenFunc, chunkBytes int, maxBytes int64) *Uploader {
	return &Uploader{
		cli:         cli,
		directiveID: directiveID,
		tokenFn:     tokenFn,
		chunkBytes:  chunkBytes,
		maxBytes:    maxBytes,
	}
}

func (u *Uploader) StdoutTruncated() bool { return u.stdoutTruncated.Load() }
func (u *Uploader) StderrTruncated() bool { return u.stderrTruncated.Load() }

func (u *Uploader) Consume(ctx context.Context, stream string, r io.Reader) error {
	buf := make([]byte, u.chunkBytes)

	for {
		n, err := r.Read(buf)
		if n > 0 {
			u.ingestBytes(ctx, stream, buf[:n])
		}
		if err != nil {
			if err == io.EOF {
				return nil
			}
			return err
		}
	}
}

// UploadBytes uploads a byte slice as one or more log chunks.
// This is useful for structured messages generated by Nexus itself (e.g., prepare errors),
// without needing an io.Reader stream.
func (u *Uploader) UploadBytes(ctx context.Context, stream string, b []byte) {
	if len(b) == 0 {
		return
	}

	for len(b) > 0 {
		n := len(b)
		if u.chunkBytes > 0 && n > u.chunkBytes {
			n = u.chunkBytes
		}
		chunk := b[:n]
		b = b[n:]

		u.ingestBytes(ctx, stream, chunk)
	}
}

type OverflowInfo struct {
	Enabled           bool
	StdoutPath        string
	StderrPath        string
	StdoutBytes       int64
	StderrBytes       int64
	MaxBytesPerStream int64
}

// EnableOverflow enables disk overflow capture for bytes beyond MaxOutputBytes.
// dir must be a directive-specific host directory. Files are created lazily:
//   - <dir>/stdout.log
//   - <dir>/stderr.log
func (u *Uploader) EnableOverflow(dir string, maxBytesPerStream int64) {
	if dir == "" || maxBytesPerStream <= 0 {
		return
	}

	u.overflowEnabled = true
	u.overflowDir = dir
	u.stdoutOverflow = overflowStream{
		path:     filepath.Join(dir, "stdout.log"),
		maxBytes: maxBytesPerStream,
	}
	u.stderrOverflow = overflowStream{
		path:     filepath.Join(dir, "stderr.log"),
		maxBytes: maxBytesPerStream,
	}
}

func (u *Uploader) OverflowInfo() OverflowInfo {
	info := OverflowInfo{Enabled: u.overflowEnabled}
	if !u.overflowEnabled {
		return info
	}

	u.stdoutOverflow.mu.Lock()
	info.StdoutPath = u.stdoutOverflow.path
	info.StdoutBytes = u.stdoutOverflow.bytes
	info.MaxBytesPerStream = u.stdoutOverflow.maxBytes
	u.stdoutOverflow.mu.Unlock()

	u.stderrOverflow.mu.Lock()
	info.StderrPath = u.stderrOverflow.path
	info.StderrBytes = u.stderrOverflow.bytes
	if info.MaxBytesPerStream == 0 {
		info.MaxBytesPerStream = u.stderrOverflow.maxBytes
	}
	u.stderrOverflow.mu.Unlock()

	return info
}

func (u *Uploader) Close() error {
	var stdoutErr error
	u.stdoutOverflow.mu.Lock()
	if u.stdoutOverflow.file != nil {
		stdoutErr = u.stdoutOverflow.file.Close()
		u.stdoutOverflow.file = nil
	}
	u.stdoutOverflow.mu.Unlock()

	var stderrErr error
	u.stderrOverflow.mu.Lock()
	if u.stderrOverflow.file != nil {
		stderrErr = u.stderrOverflow.file.Close()
		u.stderrOverflow.file = nil
	}
	u.stderrOverflow.mu.Unlock()

	return errors.Join(stdoutErr, stderrErr)
}

func (u *Uploader) markTruncated(stream string) {
	switch stream {
	case "stdout":
		u.stdoutTruncated.Store(true)
	case "stderr":
		u.stderrTruncated.Store(true)
	}
}

func (u *Uploader) ingestBytes(ctx context.Context, stream string, b []byte) {
	if stream != "stdout" && stream != "stderr" {
		return
	}

	accepted := u.acceptBytes(int64(len(b)))
	if accepted <= 0 {
		u.markTruncated(stream)
		u.writeOverflow(stream, b)
		return
	}

	chunk := b
	truncated := false
	if int64(len(b)) > accepted {
		chunk = b[:accepted]
		truncated = true
		u.markTruncated(stream)
		u.writeOverflow(stream, b[accepted:])
	}

	seq := u.nextSeq(stream)

	enc := base64.StdEncoding.EncodeToString(chunk)
	req := protocol.LogChunkRequest{
		Stream:      stream,
		Seq:         seq,
		BytesBase64: enc,
		Truncated:   truncated,
	}
	reqCtx, cancel := client.WithTimeout(ctx)
	defer cancel()
	_ = u.cli.LogChunk(reqCtx, u.directiveID, u.tokenFn(), req) // best-effort
}

type overflowStream struct {
	mu sync.Mutex

	path     string
	maxBytes int64

	file  *os.File
	bytes int64
	ended bool
}

func (u *Uploader) writeOverflow(stream string, b []byte) {
	if !u.overflowEnabled || len(b) == 0 {
		return
	}

	var s *overflowStream
	switch stream {
	case "stdout":
		s = &u.stdoutOverflow
	case "stderr":
		s = &u.stderrOverflow
	default:
		return
	}

	s.mu.Lock()
	defer s.mu.Unlock()

	if s.ended {
		return
	}

	remaining := s.maxBytes - s.bytes
	if remaining <= 0 {
		s.ended = true
		return
	}

	if s.file == nil {
		if err := os.MkdirAll(filepath.Dir(s.path), 0o755); err != nil {
			// Fail-open: overflow capture is best-effort.
			return
		}
		// Refuse to follow symlinks: a sandbox process could create a symlink
		// at the overflow path to redirect writes to an arbitrary host file.
		if fi, err := os.Lstat(s.path); err == nil && fi.Mode()&os.ModeSymlink != 0 {
			s.ended = true
			return
		}
		f, err := os.OpenFile(s.path, os.O_CREATE|os.O_APPEND|os.O_WRONLY, 0o644)
		if err != nil {
			return
		}
		s.file = f
	}

	toWrite := b
	if int64(len(b)) > remaining {
		toWrite = b[:remaining]
		s.ended = true
	}

	if _, err := s.file.Write(toWrite); err != nil {
		return
	}
	s.bytes += int64(len(toWrite))

	if s.ended {
		_, _ = s.file.WriteString(fmt.Sprintf("\n[nexus] overflow file reached max_bytes_per_stream=%d\n", s.maxBytes))
	}
}

func (u *Uploader) acceptBytes(n int64) int64 {
	if n <= 0 {
		return 0
	}
	if u.maxBytes <= 0 {
		return n
	}

	for {
		cur := atomic.LoadInt64(&u.totalBytes)
		remaining := u.maxBytes - cur
		if remaining <= 0 {
			return 0
		}

		take := n
		if take > remaining {
			take = remaining
		}

		if atomic.CompareAndSwapInt64(&u.totalBytes, cur, cur+take) {
			return take
		}
	}
}

func (u *Uploader) nextSeq(stream string) int {
	switch stream {
	case "stdout":
		return int(atomic.AddInt32(&u.stdoutSeq, 1) - 1)
	case "stderr":
		return int(atomic.AddInt32(&u.stderrSeq, 1) - 1)
	default:
		return -1
	}
}
